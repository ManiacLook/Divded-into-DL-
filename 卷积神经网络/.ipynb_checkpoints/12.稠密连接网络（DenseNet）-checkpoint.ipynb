{
 "cells": [
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "f7f13900",
   "metadata": {},
   "source": [
    "`ResNet`中的跨层连接设计引申出了数个后续工作。本节我们介绍其中的一个：稠密连接网络（`DenseNet`）。 它与`ResNet`的主要区别如图所示。\n",
    "![image.png](attachment:image.png)\n",
    "图中将部分前后相邻的运算抽象为模块A和模块B。与`ResNet`的主要区别在于，`DenseNet`里模块B的输出不是像`ResNet`那样和模块A的输出相加，而是在通道维上连结。这样模块A的输出可以直接传入模块B后面的层。在这个设计里，模块A直接跟模块B后面的所有层连接在了一起。这也是它被称为“稠密连接”的原因。\n",
    "\n",
    "`DenseNet`的主要构建模块是稠密块（dense block）和过渡层（transition layer）。前者定义了输入和输出是如何连结的，后者则用来控制通道数，使之不过大。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52afd52f",
   "metadata": {},
   "source": [
    "# 稠密块\n",
    "`DenseNet`使用了`ResNet`改良版的“批量归一化、激活和卷积”结构，我们首先在`conv_block`函数里实现这个结构。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e17f3e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../深度学习基础/\") \n",
    "import d2lzh_pytorch as d2l\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a351b6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(in_channels, out_channels):\n",
    "    blk = nn.Sequential(\n",
    "        nn.BatchNorm2d(in_channels),\n",
    "        nn.ReLU(),\n",
    "        nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)\n",
    "    )\n",
    "    return blk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1077eff",
   "metadata": {},
   "source": [
    "稠密块由多个`conv_block`组成，每块使用相同的输出通道数。但在前向计算时，我们将每块的输入和输出在通道维上连结。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69e6ede8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseBlock(nn.Module):\n",
    "    def __init__(self, num_convs, in_channels, out_channels):\n",
    "        super(DenseBlock, self).__init__()\n",
    "        net = []\n",
    "        for i in range(num_convs):\n",
    "            in_c = in_channels + i * out_channels\n",
    "            net.append(conv_block(in_c, out_channels))\n",
    "        self.net = nn.ModuleList(net)\n",
    "        self.out_channels = in_channels + num_convs * out_channels  # 计算输出通道数\n",
    "    \n",
    "    def forward(self, X):\n",
    "        for blk in self.net:\n",
    "            Y = blk(X)\n",
    "            X = torch.cat((X, Y), dim=1)  # 在通道维上将输入和输出连结\n",
    "        return X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c08e05a",
   "metadata": {},
   "source": [
    "在下面的例子中，我们定义一个有2个输出通道数为10的卷积块。使用通道数为3的输入时，我们会得到通道数为3+2×10=23的输出。卷积块的通道数控制了输出通道数相对于输入通道数的增长，因此也被称为增长率（growth rate）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a6a7c4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 23, 8, 8])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blk = DenseBlock(2, 3, 10)\n",
    "X = torch.rand(4, 3, 8, 8)\n",
    "Y = blk(X)\n",
    "Y.shape  # torch.Size([4, 23, 8, 8])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b3443bd",
   "metadata": {},
   "source": [
    "# 过渡层\n",
    "由于每个稠密块都会带来通道数的增加，使用过多则会带来过于复杂的模型。过渡层用来控制模型复杂度。它通过`1×1`卷积层来减小通道数，并使用步幅为2的平均池化层减半高和宽，从而进一步降低模型复杂度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b85a96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transition_block(in_channels, out_channels):\n",
    "    blk = nn.Sequential(\n",
    "        nn.BatchNorm2d(in_channels),\n",
    "        nn.ReLU(),\n",
    "        nn.Conv2d(in_channels, out_channels, kernel_size=1),\n",
    "        nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "    )\n",
    "    return blk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d17f019",
   "metadata": {},
   "source": [
    "对上一个例子中稠密块的输出使用通道数为10的过渡层。此时输出的通道数减为10，高和宽均减半。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "41d841a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 10, 4, 4])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blk = transition_block(23, 10)\n",
    "blk(Y).shape  # torch.Size([4, 10, 4, 4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "579a1074",
   "metadata": {},
   "source": [
    "# DenseNet模型\n",
    "我们来构造`DenseNet`模型。`DenseNet`首先使用同`ResNet`一样的单卷积层和最大池化层。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5acd412e",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = nn.Sequential(\n",
    "    nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3),\n",
    "    nn.BatchNorm2d(64),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c0836ef",
   "metadata": {},
   "source": [
    "类似于`ResNet`接下来使用的4个残差块，`DenseNet`使用的是4个稠密块。同`ResNet`一样，我们可以设置每个稠密块使用多少个卷积层。这里我们设成4，从而与上一节的`ResNet-18`保持一致。稠密块里的卷积层通道数（即增长率）设为32，所以每个稠密块将增加128个通道。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c0e4dc36",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_channels, growth_rate = 64, 32  # num_channels为当前的通道数\n",
    "num_convs_in_dense_blocks = [4, 4, 4, 4]\n",
    "\n",
    "for i, num_convs in enumerate(num_convs_in_dense_blocks):\n",
    "    DB = DenseBlock(num_convs, num_channels, growth_rate)\n",
    "    net.add_module(\"DenseBlosk_%d\" % i, DB)\n",
    "    # 上一个稠密块的输出通道数\n",
    "    num_channels = DB.out_channels\n",
    "    # 在稠密块之间加入通道数减半的过渡层\n",
    "    if i != len(num_convs_in_dense_blocks) - 1:\n",
    "        net.add_module(\"transition_block_%d\" % i, transition_block(num_channels, num_channels // 2))\n",
    "        num_channels = num_channels // 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e04d5c37",
   "metadata": {},
   "source": [
    "同`ResNet`一样，最后接上全局池化层和全连接层来输出。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "284d2561",
   "metadata": {},
   "outputs": [],
   "source": [
    "net.add_module(\"BN\", nn.BatchNorm2d(num_channels))\n",
    "net.add_module(\"relu\", nn.ReLU())\n",
    "net.add_module(\"global_avg_pool\", d2l.GlobalAvgPool2d()) # GlobalAvgPool2d的输出: (Batch, num_channels, 1, 1)\n",
    "net.add_module(\"fc\", nn.Sequential(d2l.FlattenLayer(), nn.Linear(num_channels, 10))) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c5dd90",
   "metadata": {},
   "source": [
    "我们尝试打印每个子模块的输出维度确保网络无误："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cfc35caf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  output shape:\t torch.Size([1, 64, 48, 48])\n",
      "1  output shape:\t torch.Size([1, 64, 48, 48])\n",
      "2  output shape:\t torch.Size([1, 64, 48, 48])\n",
      "3  output shape:\t torch.Size([1, 64, 24, 24])\n",
      "DenseBlosk_0  output shape:\t torch.Size([1, 192, 24, 24])\n",
      "transition_block_0  output shape:\t torch.Size([1, 96, 12, 12])\n",
      "DenseBlosk_1  output shape:\t torch.Size([1, 224, 12, 12])\n",
      "transition_block_1  output shape:\t torch.Size([1, 112, 6, 6])\n",
      "DenseBlosk_2  output shape:\t torch.Size([1, 240, 6, 6])\n",
      "transition_block_2  output shape:\t torch.Size([1, 120, 3, 3])\n",
      "DenseBlosk_3  output shape:\t torch.Size([1, 248, 3, 3])\n",
      "BN  output shape:\t torch.Size([1, 248, 3, 3])\n",
      "relu  output shape:\t torch.Size([1, 248, 3, 3])\n",
      "global_avg_pool  output shape:\t torch.Size([1, 248, 1, 1])\n",
      "fc  output shape:\t torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "X = torch.rand((1, 1, 96, 96))\n",
    "for name, layer in net.named_children():\n",
    "    X = layer(X)\n",
    "    print(name, ' output shape:\\t', X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c40f609c",
   "metadata": {},
   "source": [
    "# 获取数据并训练模型\n",
    "由于这里使用了比较深的网络，本节里我们将输入高和宽从224降到96来简化计算。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "313f393b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on  cuda\n",
      "epoch 1, loss 0.4609, train acc 0.837, test acc 0.843, time 29.5 sec\n",
      "epoch 2, loss 0.2738, train acc 0.900, test acc 0.886, time 23.3 sec\n",
      "epoch 3, loss 0.2345, train acc 0.914, test acc 0.887, time 22.3 sec\n",
      "epoch 4, loss 0.2101, train acc 0.924, test acc 0.909, time 22.2 sec\n",
      "epoch 5, loss 0.1906, train acc 0.930, test acc 0.915, time 22.4 sec\n"
     ]
    }
   ],
   "source": [
    "batch_size = 256\n",
    "# 如出现“out of memory”的报错信息，可减小batch_size或resize\n",
    "train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size, resize=96)\n",
    "\n",
    "lr, num_epochs = 0.001, 5\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "d2l.train_ch5(net, train_iter, test_iter, batch_size, optimizer, device, num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6731031f",
   "metadata": {},
   "source": [
    "# 小结\n",
    "+ 在跨层连接上，不同于`ResNet`中将输入与输出相加，`DenseNet`在通道维上连结输入与输出。\n",
    "+ `DenseNet`的主要构建模块是稠密块和过渡层。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
